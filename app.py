# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/138fdnDe6aduM9sPpxnbvJGLIH5gtg-96
"""

import streamlit as st
from pypdf import PdfReader
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from groq import Groq

# ---------------------------
# Load Groq API Key
# ---------------------------
groq_api_key = st.secrets["GROQ_API_KEY"]
client = Groq(api_key=groq_api_key)

def get_llm_answer(question, context):
    prompt = f"""
    You are an expert on the Indian Constitution.
    Use the below context to answer accurately.

    CONTEXT:
    {context}

    QUESTION:
    {question}

    ANSWER:
    """
    response = client.chat.completions.create(
        model="llama-3.1-8b-instant",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message["content"]

# ---------------------------
# Vector DB Builder
# ---------------------------
@st.cache_resource
def load_vector_db(pdf_file):
    reader = PdfReader(pdf_file)
    text = ""
    for page in reader.pages:
        text += page.extract_text()

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=150
    )
    chunks = splitter.split_text(text)

    # Embedding model (correct import now)
    embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

    # FIX: Correct FAISS builder
    db = FAISS.from_texts(chunks, embedding_model)

    return db, chunks


# ---------------------------
# Streamlit UI
# ---------------------------
st.title("ðŸ“˜ Indian Constitution QA App")

uploaded_pdf = st.file_uploader("Upload Constitution PDF", type=["pdf"])

if uploaded_pdf:
    st.success("PDF loaded! Creating Vector Storeâ€¦ (1st time only)")

    vectordb, chunks = load_vector_db(uploaded_pdf)

    question = st.text_input("Ask any question about the Constitution:")

    if question:
        docs = vectordb.similarity_search(question, k=8)
        context = "\n\n".join([d.page_content for d in docs])

        st.write("### ðŸ“Œ Answer:")
        answer = get_llm_answer(question, context)
        st.write(answer)
